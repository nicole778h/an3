# -*- coding: utf-8 -*-
"""lab2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iMG1MRoIPxmrybKn4-NTpt8bixug_MES
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer
from sklearn.impute import KNNImputer
from sklearn.ensemble import IsolationForest
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.decomposition import PCA

df = pd.read_csv("gha_accra.licorr.stats.csv")

# 2. Explorarea inițială a setului de date
print("Primele 5 rânduri:")
print(df.head())
print("\nInformații despre setul de date:")
print(df.info())
print("\nStatistici descriptive:")
print(df.describe())

# 3. Identificarea și tratarea valorilor lipsă
missing_values = df.isnull().sum()
print("\nValori lipsă per coloană:")
print(missing_values[missing_values > 0])

# Metoda 1: Umplem valorile lipsă cu media doar pentru coloanele numerice
df.fillna(df.select_dtypes(include=[np.number]).mean(), inplace=True)

# Metoda 2: Utilizarea KNN pentru imputarea valorilor lipsă
imputer = KNNImputer(n_neighbors=5)
df_imputed = pd.DataFrame(imputer.fit_transform(df.select_dtypes(include=[np.number])), columns=df.select_dtypes(include=[np.number]).columns)
df.update(df_imputed)

# 4. Identificarea și tratarea outlierilor folosind IQR, Z-score și Isolation Forest


df_numeric = df.select_dtypes(include=[np.number])

# Calculul cuantilelor pentru coloanele numerice
Q1 = df_numeric.quantile(0.25)
Q3 = df_numeric.quantile(0.75)
IQR = Q3 - Q1

# Eliminarea outlierilor folosind IQR
df_no_outliers = df_numeric[~((df_numeric < (Q1 - 1.5 * IQR)) | (df_numeric > (Q3 + 1.5 * IQR))).any(axis=1)]
print(f"\nNumărul de rânduri după eliminarea outlierilor (IQR): {df_no_outliers.shape[0]}")

# Aplicăm Isolation Forest pentru detectarea outlierilor
iso_forest = IsolationForest(contamination=0.05)
outlier_preds = iso_forest.fit_predict(df_numeric)
df = df[outlier_preds == 1]

# 5. Vizualizări pentru înțelegerea relațiilor

#  coloanele numerice pentru a calcula corelațiile
df_numeric = df.select_dtypes(include=[np.number])

# Heatmap pentru corelația dintre variabile (doar pe date numerice)
plt.figure(figsize=(12,6))
sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Heatmap - Corelația dintre variabile")
plt.show()

# Distribuția populației în 2018
plt.figure(figsize=(10,5))
sns.histplot(df["pop2018"], bins=30, kde=True)
plt.title("Distribuția populației în 2018")
plt.show()

# BoxPlot pentru detectarea outlierilor
plt.figure(figsize=(10,5))
sns.boxplot(data=df_numeric)
plt.xticks(rotation=90)
plt.title("Boxplot pentru detectarea outlierilor")
plt.show()

# Scatterplot pentru relații între variabile
plt.figure(figsize=(8,6))
sns.scatterplot(x=df["pt_lon"], y=df["licorr_slope"], hue=df["pop2018"], palette="coolwarm")
plt.title("Scatterplot între longitudine, panta luminoasă și populație")
plt.show()

# 6. Preprocesarea datelor - Standardizare, Normalizare și Discretizare
scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df.select_dtypes(include=[np.number])), columns=df.select_dtypes(include=[np.number]).columns)

normalizer = Normalizer(norm='l2')
df_normalized = pd.DataFrame(normalizer.fit_transform(df_scaled), columns=df_scaled.columns)

print("\nDatele au fost scalate utilizând StandardScaler și normalizate folosind L2 norm.")

# 7. Feature Engineering - Selecția și extracția caracteristicilor
selector = SelectKBest(score_func=f_classif, k=5)
df_selected = selector.fit_transform(df_scaled, df["pop2018"])
print("Cele mai relevante 5 caracteristici au fost selectate.")

# Reducerea dimensionalității cu PCA
pca = PCA(n_components=3)
df_pca = pca.fit_transform(df_scaled)
print("Reducerea dimensionalității cu PCA la 3 componente.")

# 8. Salvăm setul de date preprocesat
df_normalized.to_csv("processed_data.csv", index=False)
print("Setul de date preprocesat a fost salvat ca 'processed_data.csv'.")